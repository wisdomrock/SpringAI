spring:
  ai:
    openai:
      chat:
        base-url: http://localhost:12434/engines #local open-ai in docker
        options:
          model: ai/gemma3
    chat:
      client:
        enabled: true

  autoconfigure:
    exclude:
      - org.springframework.ai.model.ollama.autoconfigure.OllamaChatAutoConfiguration
      - org.springframework.ai.model.ollama.autoconfigure.OllamaEmbeddingAutoConfiguration
      - org.springframework.ai.model.bedrock.converse.autoconfigure.BedrockConverseProxyChatAutoConfiguration